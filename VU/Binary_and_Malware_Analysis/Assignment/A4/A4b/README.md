# Run my implementation
To run my solution, in each folder, there is a script called `script_final.sh`.
Read the Script paragraph to understand what the other scripts do.

# Data flow Analysis
I started implementing the data flow analysis.
I created a Ghidra script in python to "simulate" the PIN tool behavior to instrument each instructions in all the functions within the array and propagate the taint if needed.

By analyzing some of the functions in Ghidra, I understood that in each function the input value is stored in `RDI` and the output value is contained in `RAX`.
Thus, a washer function is one in which if at the beginning of it `RDI` is tainted, then before return `RAX` is also tainted.
Whereas, in contrast, in a fake washer function `RAX` at the end is not tainted.

In my script I created 2 classes, a Registers class to manage the taint state of registers (at the start I supposed that only `RDI` is tainted), and the Stack class to handle stack operations (`PUSH` and `POP`).
Then, I disassembled each instruction of each function to "instrument" all the possible types of instructions and to propagate the taint where needed.
As I said before, when I "instrumented" each function, only `RDI` is tainted. 
Then for example I checked if the current instruction was a `MOV`, I verified if both the operands were registers and I checked if the source operand was tainted, and if so, I propagated the taint the destination operand as well. In the same way, I implemented also the `XOR` and `ADD` instructions.
For the `PUSH` and `POP` instructions, I pushed and popped the register within my stack and for the `INC` and `SHL` instructions I checked if the operand was a register and it was tainted, and if so I kept the taint to the register.
Then, at the `RET` instruction I saved the function within the washer functions array if `RAX` was tainted or I saved the function inside the fake washer functions array if `RAX` wasn't tainted.
At the end of all functions I thus generated two arrays containing all washer functions and fake washer functions and I also save them in 2 different text files.

## PIN tool
I modified my PIN tool to save in 2 vectors, washers and fake washers, all the functions within the 2 text files generated with my Ghidra script.
Then, to properly propagate and clear the taint, I instrumented each `CALL` and `RET`.

For each `CALL`:

- I checked if the target of the `CALL` was one of the functions inside my washers vector, and if so, I controlled if `RDI` was tainted and then I stored the tainted value inside a global array to keep track of it and use it during the `RET` and I also set a boolean global variable `checkWash` to true.
- On the other hand, I checked if the target of the `CALL` was within my fake washers vector and then I set a boolean global variable `checkFake` to true.

For each `RET`:

- I controlled if the `checkWash` variable was true, meaning that before this `RET` there was a `CALL` for a function among the washer functions, and if so, I propagated the taint by setting `RAX` to the taint value stored in my global array. Finally, I set again `checkWash` to false.
- I handled the fake washer functions with exactly the same logic, but here I cleared the taint, so I set `RAX` to 0.

I used the same PIN tool also for the CFG analysis.

# CFG Analysis
Having already done the data flow analysis, I had already classified the functions into washers and fake washers.
In my Ghidra script I extracted for each function 2 CFG properties: the number of edges (by counting the number of unique `JMP` instructions) and the number of blocks (using the API described during the static analysis automation lecture).

So, for each function I iterated on each instruction, and then I got the mnemonic string for each of them. After that, I checked whether the mnemonic string started with `J` and if so, I incremented the `JMP` counter.
At the end of each function, I saved all functions having the same number of `JMP`s in different text files.

In the same way, I saved in different text files all the functions that have a certain amount of blocks. To find the number of blocks I used the APIs provided during the static analysis automation lecture.
After that, I created all possible combinations between functions with 4, 5, and 6 `JMP`s and functions with 4, 5, 6, 7, and 8 blocks.
Then, by analyzing the `CFG`s of the functions classified with the data flow analysis, and confirming what I understood by comparing the combinations created with `JMP`s and blocks with the classification of the data flow analysis, I realized that only the washer functions had 5 `JMP`s and 8 blocks, while all the others had other types of combinations. In this way I classified the functions into washers and fake washers.

Finally, I used the PIN tool to propagate the taint and clean them, as described for the data flow analysis.

# Script
In the 2 folders you can find the:

- `ghidra_headless` folder that contains the Ghidra script (cfg.py and data_flow.py respectively)
- `run_ghidra_script_cfg.sh` and `run_ghidra_script_dataflow.sh` that run the Ghidra scripts
- `taintool.cpp` script (with the modifications described in the data flow section) 
- `generate_input_secret.py`that is the script from the third assignment that parses the PIN tool output and generates the `input_secret.txt` file
- `script_final.sh` that automates everything

Since I did not complete the advance obfuscation in assignment 3, even though I did all the points for this assignment, I was unable to generate the `output_secret.txt`.

# Question
## A
By using MemPick, which is specialized in analyzing dynamically allocated data structures, we should be able to identify the following structures and fields:

Regarding the struct `graph`:

- Pointer to struct `graph` (the main allocated graph structure)
- Array `alist` (the arrays of `alist` pointers within the graph structure)
- the `successors` structure:
  the dynamically allocated instances of the successors structure, which contain the fields `d`, `len`, `is_sorted`, and `list

Instead for struct `search_info`:

- Pointer to struct `search_info`: 
  MemPick will be able to find the allocation of struct `search_info`.
- Dynamic arrays (the `preorder`, `time`, `parent`, and `depth` dynamic arrays)
  
Instead, using Howard, which is able to trace the flow of data and resolve types, we should be able to determine the types of data and their connections, thus allowing us to identify:

- the pointers to the `graph` and `search_info` structures
- the fields of the structures: 
  by tracking data usage, we can find the specific types of fields within the structures (since all the fields inside the structures are accessed inside the methods of the 2 classes)

In addition, Howard could trace how the `graph` and `successors` structures are connected through the `alist` fields and, finally, the use and size of dynamic arrays within the `search_info` structure.

## B
By also instrumenting glibc from the analysis you would be able to get more detailed information about memory management and allocation patterns, as you could trace every call to `malloc`, `realloc` and `free`, getting a complete view of all memory management operations.


